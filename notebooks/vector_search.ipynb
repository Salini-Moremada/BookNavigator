{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-25T09:33:01.575619Z",
     "start_time": "2025-09-25T09:32:46.767910Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings  # updated import\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\Book Sphere\\data\\books_cleaned.csv\")\n",
    "print(books.head())\n",
    "\n",
    "with open(\"tagged_description.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in books[\"tagged_description\"].tolist():\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load document\n",
    "raw_documents = TextLoader(\"tagged_description.txt\", encoding=\"utf-8\").load()\n",
    "\n",
    "# Manually split by newline (like chunk_size=0)\n",
    "documents = []\n",
    "for doc in raw_documents:\n",
    "    lines = doc.page_content.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if line.strip():  # skip empty lines\n",
    "            documents.append(Document(page_content=line))\n",
    "\n",
    "print(f\"Total chunks created: {len(documents)}\")\n",
    "\n",
    "documents[0]\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Initialize HuggingFace embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Example usage with Chroma\n",
    "texts = [\"This is a book about AI.\", \"This is a novel about love.\"]\n",
    "db = Chroma.from_texts(texts, embeddings, persist_directory=\"db_books\")\n",
    "\n",
    "# Test search\n",
    "query = \"romantic stories\"\n",
    "results = db.similarity_search(query, k=1)\n",
    "print(results)\n",
    "\n",
    "\n",
    "\n",
    "!pip install -U ipywidgets\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Initialize HuggingFace embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Example usage with Chroma\n",
    "texts = [\"This is a book about AI.\", \"This is a novel about love.\"]\n",
    "db = Chroma.from_texts(texts, embeddings, persist_directory=\"db_books\")\n",
    "\n",
    "# Test search\n",
    "query = \"romantic stories\"\n",
    "results = db.similarity_search(query, k=10)\n",
    "print(results)\n",
    "\n",
    "query = \"romantic stories\"\n",
    "results = db.similarity_search(query, k=1)  # or k=10\n",
    "\n",
    "# The first document\n",
    "first_doc = results[0]\n",
    "\n",
    "print(first_doc.page_content)\n",
    "\n",
    "isbn_str = first_doc.page_content.split(\"\\n\")[0].strip()\n",
    "\n",
    "try:\n",
    "    isbn_num = int(isbn_str)\n",
    "except ValueError:\n",
    "    print(f\"Cannot convert ISBN to int: {isbn_str}\")\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Create documents with ISBNs in metadata\n",
    "documents = []\n",
    "for idx, row in books.iterrows():\n",
    "    documents.append(\n",
    "        Document(\n",
    "            page_content=row['tagged_description'],\n",
    "            metadata={\"isbn13\": row['isbn13']}\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Build Chroma DB from these documents\n",
    "db = Chroma.from_documents(documents, embeddings, persist_directory=\"db_books\")\n",
    "\n",
    "# Example search\n",
    "query = \"romantic stories\"\n",
    "results = db.similarity_search(query, k=1)\n",
    "\n",
    "# Get ISBN from metadata\n",
    "first_doc = results[0]\n",
    "isbn_num = first_doc.metadata[\"isbn13\"]\n",
    "print(\"Matched ISBN:\", isbn_num)\n",
    "\n",
    "# Get book info from DataFrame\n",
    "matched_books = books[books[\"isbn13\"] == isbn_num]\n",
    "print(matched_books)\n",
    "\n",
    "# Example: search query\n",
    "query = \"books for babies about animals\"\n",
    "docs = db.similarity_search(query, k=10)\n",
    "\n",
    "# Suppose the ISBN is the first number in the document content\n",
    "doc_content = docs[0].page_content.strip()\n",
    "\n",
    "# Remove extra spaces and split if needed\n",
    "isbn_num = ''.join(filter(str.isdigit, doc_content))  # keep only digits\n",
    "isbn_num = int(isbn_num)\n",
    "\n",
    "matched_books = books[books[\"isbn13\"] == isbn_num]\n",
    "\n",
    "print(matched_books)\n",
    "\n",
    "doc_content = docs[0].page_content.strip()\n",
    "isbn_str = doc_content.split()[0]  # take first word if ISBN is at start\n",
    "isbn_num = int(''.join(filter(str.isdigit, isbn_str)))  # keep only digits\n",
    "\n",
    "matched_books = books[books[\"isbn13\"] == isbn_num]\n",
    "print(matched_books)\n",
    "\n",
    "\n",
    "# Function to retrieve semantic recommendations\n",
    "def retrieve_semantic_recommendations(query: str, top_k: int = 10) -> pd.DataFrame:\n",
    "    # Step 1: Semantic search in Chroma DB\n",
    "    recs = db_books.similarity_search(query, k=50)  # search top 50 similar docs\n",
    "\n",
    "    # Step 2: Extract ISBNs from the search results\n",
    "    books_list = []\n",
    "    for doc in recs[8:]:  # skip first 8 if needed\n",
    "        try:\n",
    "            isbn_str = doc.page_content.strip().split()[0]\n",
    "            isbn_num = int(''.join(filter(str.isdigit, isbn_str)))\n",
    "            books_list.append(isbn_num)\n",
    "        except:\n",
    "            continue  # skip if conversion fails\n",
    "\n",
    "    # Step 3: Return matching books from CSV\n",
    "    return books[books[\"isbn13\"].isin(books_list)].head(top_k)\n",
    "\n",
    "\n",
    "recommendations = retrieve_semantic_recommendations(\"A book to teach children about animals\")\n",
    "print(recommendations)\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Assuming you already have your documents split into 'documents'\n",
    "# or you can use your texts column from the CSV\n",
    "texts = books[\"tagged_description\"].tolist()\n",
    "\n",
    "# Build/load Chroma DB\n",
    "db_books = Chroma.from_texts(texts, embeddings, persist_directory=\"db_books\")\n",
    "\n",
    "# Optional: persist the database (Chroma auto-persists in newer versions)\n",
    "db_books.persist()\n",
    "\n",
    "recommendations = retrieve_semantic_recommendations(\"A book to teach children about animals\")\n",
    "print(recommendations)\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "def retrieve_semantic_recommendations(query: str, db: Chroma, books_df: pd.DataFrame, top_k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform semantic search on a book vector database and return top matching books.\n",
    "\n",
    "    Parameters:\n",
    "        query (str): User query string.\n",
    "        db (Chroma): Chroma vector database containing book embeddings.\n",
    "        books_df (pd.DataFrame): Original book dataset with ISBNs and metadata.\n",
    "        top_k (int): Number of recommendations to return.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Top-k recommended books with full metadata.\n",
    "    \"\"\"\n",
    "    # Step 1: Semantic search\n",
    "    recs = db.similarity_search(query, k=50)  # Search top 50 similar documents\n",
    "\n",
    "    # Step 2: Extract ISBNs safely\n",
    "    isbn_list = []\n",
    "    for doc in recs:\n",
    "        text = doc.page_content.strip()\n",
    "        # Attempt to extract numeric ISBN from the start of the text\n",
    "        parts = text.split()\n",
    "        if parts:\n",
    "            isbn_str = ''.join(filter(str.isdigit, parts[0]))\n",
    "            if isbn_str.isdigit():\n",
    "                isbn_list.append(int(isbn_str))\n",
    "\n",
    "    # Step 3: Filter books by ISBN and return top_k\n",
    "    recommended_books = books_df[books_df[\"isbn13\"].isin(isbn_list)].head(top_k)\n",
    "\n",
    "    return recommended_books\n",
    "\n",
    "\n",
    "# Make sure db_books is your Chroma vector store and books is your DataFrame\n",
    "query = \"A book to teach children about animals\"\n",
    "recommendations = retrieve_semantic_recommendations(query, db_books, books, top_k=10)\n",
    "print(recommendations)\n",
    "\n",
    "query = \"Stories about friendship and adventure\"\n",
    "recommendations = retrieve_semantic_recommendations(query, db_books, books, top_k=5)\n",
    "print(recommendations)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\Desktop\\BookNavigator\\.venv1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          isbn13      isbn10                title  \\\n",
      "0  9780002005883  0002005883               Gilead   \n",
      "1  9780002261982  0002261987         Spider's Web   \n",
      "2  9780006178736  0006178731       Rage of angels   \n",
      "3  9780006280897  0006280897       The Four Loves   \n",
      "4  9780006280934  0006280935  The Problem of Pain   \n",
      "\n",
      "                           authors                     categories  \\\n",
      "0               Marilynne Robinson                        Fiction   \n",
      "1  Charles Osborne;Agatha Christie  Detective and mystery stories   \n",
      "2                   Sidney Sheldon                        Fiction   \n",
      "3              Clive Staples Lewis                 Christian life   \n",
      "4              Clive Staples Lewis                 Christian life   \n",
      "\n",
      "                                           thumbnail  \\\n",
      "0  http://books.google.com/books/content?id=KQZCP...   \n",
      "1  http://books.google.com/books/content?id=gA5GP...   \n",
      "2  http://books.google.com/books/content?id=FKo2T...   \n",
      "3  http://books.google.com/books/content?id=XhQ5X...   \n",
      "4  http://books.google.com/books/content?id=Kk-uV...   \n",
      "\n",
      "                                         description  published_year  \\\n",
      "0  A NOVEL THAT READERS and critics have been eag...          2004.0   \n",
      "1  A new 'Christie for Christmas' -- a full-lengt...          2000.0   \n",
      "2  A memorable, mesmerizing heroine Jennifer -- b...          1993.0   \n",
      "3  Lewis' work on the nature of love divides love...          2002.0   \n",
      "4  \"In The Problem of Pain, C.S. Lewis, one of th...          2002.0   \n",
      "\n",
      "   average_rating  num_pages  ratings_count      title_and_subtitle  \\\n",
      "0            3.85      247.0          361.0                  Gilead   \n",
      "1            3.83      241.0         5164.0  Spider's Web + A Novel   \n",
      "2            3.93      512.0        29532.0          Rage of angels   \n",
      "3            4.15      170.0        33684.0          The Four Loves   \n",
      "4            4.09      176.0        37569.0     The Problem of Pain   \n",
      "\n",
      "                                  tagged_description  \n",
      "0  9780002005883 A NOVEL THAT READERS and critics...  \n",
      "1  9780002261982 A new 'Christie for Christmas' -...  \n",
      "2  9780006178736 A memorable, mesmerizing heroine...  \n",
      "3  9780006280897 Lewis' work on the nature of lov...  \n",
      "4  9780006280934 \"In The Problem of Pain, C.S. Le...  \n",
      "Total chunks created: 5197\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\BookNavigator\\.venv1\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:83\u001B[39m, in \u001B[36mChroma.__init__\u001B[39m\u001B[34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001B[39m\n\u001B[32m     82\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mchromadb\u001B[39;00m\n\u001B[32m     84\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mchromadb\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfig\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 42\u001B[39m\n\u001B[32m     40\u001B[39m \u001B[38;5;66;03m# Example usage with Chroma\u001B[39;00m\n\u001B[32m     41\u001B[39m texts = [\u001B[33m\"\u001B[39m\u001B[33mThis is a book about AI.\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mThis is a novel about love.\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m---> \u001B[39m\u001B[32m42\u001B[39m db = \u001B[43mChroma\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_texts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersist_directory\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdb_books\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[38;5;66;03m# Test search\u001B[39;00m\n\u001B[32m     45\u001B[39m query = \u001B[33m\"\u001B[39m\u001B[33mromantic stories\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\BookNavigator\\.venv1\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:817\u001B[39m, in \u001B[36mChroma.from_texts\u001B[39m\u001B[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[39m\n\u001B[32m    784\u001B[39m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[32m    785\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfrom_texts\u001B[39m(\n\u001B[32m    786\u001B[39m     \u001B[38;5;28mcls\u001B[39m: Type[Chroma],\n\u001B[32m   (...)\u001B[39m\u001B[32m    796\u001B[39m     **kwargs: Any,\n\u001B[32m    797\u001B[39m ) -> Chroma:\n\u001B[32m    798\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001B[39;00m\n\u001B[32m    799\u001B[39m \n\u001B[32m    800\u001B[39m \u001B[33;03m    If a persist_directory is specified, the collection will be persisted there.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    815\u001B[39m \u001B[33;03m        Chroma: Chroma vectorstore.\u001B[39;00m\n\u001B[32m    816\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m817\u001B[39m     chroma_collection = \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    818\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    819\u001B[39m \u001B[43m        \u001B[49m\u001B[43membedding_function\u001B[49m\u001B[43m=\u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    820\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpersist_directory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpersist_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    821\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclient_settings\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclient_settings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    822\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclient\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    823\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcollection_metadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollection_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    824\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    825\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    826\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    827\u001B[39m         ids = [\u001B[38;5;28mstr\u001B[39m(uuid.uuid4()) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m texts]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\BookNavigator\\.venv1\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:226\u001B[39m, in \u001B[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    224\u001B[39m     warned = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    225\u001B[39m     emit_warning()\n\u001B[32m--> \u001B[39m\u001B[32m226\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\BookNavigator\\.venv1\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:86\u001B[39m, in \u001B[36mChroma.__init__\u001B[39m\u001B[34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001B[39m\n\u001B[32m     84\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mchromadb\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfig\u001B[39;00m\n\u001B[32m     85\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m86\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[32m     87\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mCould not import chromadb python package. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     88\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mPlease install it with `pip install chromadb`.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     89\u001B[39m     )\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m client \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     92\u001B[39m     \u001B[38;5;28mself\u001B[39m._client_settings = client_settings\n",
      "\u001B[31mImportError\u001B[39m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
